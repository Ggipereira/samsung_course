{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8QNNSrUrJ-m"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhffPUOcrJ-p"
      },
      "source": [
        "# Exercise Notebook Part 2\n",
        "\n",
        "**Practice exercises for Part 2** - Follows **Learning Notebook Part 2**\n",
        "\n",
        "This notebook covers:\n",
        "1. **Exercise 3**: TF-IDF from Scratch - IDF calculation and full TF-IDF (builds on Part 1's TF/BoW)\n",
        "2. **Exercise 4**: Build TF-IDF Vectors from Scratch - Create complete TF-IDF vectors\n",
        "3. **Exercise 5**: Similarity-Based Search with TF-IDF - Using cosine similarity for search\n",
        "4. **Exercise 6**: Hybrid Search - Combining TF-IDF + keyword matching\n",
        "5. **Exercise 7**: Compare Search Methods - Side-by-side comparison\n",
        "\n",
        "**Important Pipeline Order:**\n",
        "```\n",
        "Preprocessing ‚Üí Tokenization ‚Üí Vectorization (BoW/TF ‚Üí TF-IDF) ‚Üí Similarity Search ‚Üí Hybrid Search\n",
        "```\n",
        "\n",
        "**Instructions**: Complete each exercise by filling in the code cells marked with `# TODO`\n",
        "\n",
        "**üí° Tip**: These exercises build on each other! Start with Exercise 3, then work through them in order. If you get stuck, refer back to the Learning Notebook Part 2 for guidance.\n",
        "\n",
        "**Note**:\n",
        "- **Prerequisites**: Complete **Exercise Notebook Part 1** first! You need to understand TF/BoW before learning TF-IDF.\n",
        "- **Document clustering** is covered in **Learning Notebook Part 2** - no exercises needed here!\n",
        "- Remember that TF-IDF is **syntactic** (word-based, no meaning). True semantic search (understanding meaning, synonyms) requires embeddings (Class 3)! **Semantic = meaning**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "pj7GU_g5rJ-u",
        "outputId": "d9ec41e4-df93-4fd2-d541-9fa7741b44c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.4.0\n"
          ]
        }
      ],
      "source": [
        "# Install required packages if not already installed\n",
        "# Uncomment the line below if gensim is not installed\n",
        "# !pip install gensim\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from collections import Counter\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "uwH_U2hwrJ-x",
        "outputId": "9a376aa5-2d3c-4963-c14a-93469cba2219",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data file not found. Downloading from GitHub...\n",
            "‚úì Data file downloaded successfully!\n",
            "Loaded 10000 movies\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   movie_id                title  \\\n",
              "0         1         Edge of Code   \n",
              "1         2      Storm of Secret   \n",
              "2         3  Under Warrior Redux   \n",
              "3         4      Quest of Secret   \n",
              "4         5          Key of Game   \n",
              "\n",
              "                                         description      genre  rating  \n",
              "0  A compelling romance film about a young advent...    Romance     7.1  \n",
              "1  This captivating romance movie follows a quest...    Romance     6.3  \n",
              "2  In this captivating war story, a secret organi...        War     7.3  \n",
              "3  A compelling fantasy film about a determined d...    Fantasy     8.3  \n",
              "4  A exploration adventure film about a master th...  Adventure     6.2  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0ed4a547-8c35-4c53-9b2b-ec7899d423e7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movie_id</th>\n",
              "      <th>title</th>\n",
              "      <th>description</th>\n",
              "      <th>genre</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Edge of Code</td>\n",
              "      <td>A compelling romance film about a young advent...</td>\n",
              "      <td>Romance</td>\n",
              "      <td>7.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Storm of Secret</td>\n",
              "      <td>This captivating romance movie follows a quest...</td>\n",
              "      <td>Romance</td>\n",
              "      <td>6.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Under Warrior Redux</td>\n",
              "      <td>In this captivating war story, a secret organi...</td>\n",
              "      <td>War</td>\n",
              "      <td>7.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Quest of Secret</td>\n",
              "      <td>A compelling fantasy film about a determined d...</td>\n",
              "      <td>Fantasy</td>\n",
              "      <td>8.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Key of Game</td>\n",
              "      <td>A exploration adventure film about a master th...</td>\n",
              "      <td>Adventure</td>\n",
              "      <td>6.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0ed4a547-8c35-4c53-9b2b-ec7899d423e7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0ed4a547-8c35-4c53-9b2b-ec7899d423e7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0ed4a547-8c35-4c53-9b2b-ec7899d423e7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-743deed0-9e11-489b-910b-c3b01b1110be\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-743deed0-9e11-489b-910b-c3b01b1110be')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-743deed0-9e11-489b-910b-c3b01b1110be button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 10000,\n  \"fields\": [\n    {\n      \"column\": \"movie_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2886,\n        \"min\": 1,\n        \"max\": 10000,\n        \"num_unique_values\": 10000,\n        \"samples\": [\n          6253,\n          4685,\n          1732\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9983,\n        \"samples\": [\n          \"Agent of Hero\",\n          \"Battle Saga\",\n          \"Secret of Circle\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9136,\n        \"samples\": [\n          \"A engaging crime film about a secret organization. the film explores themes of courage and redemption.\",\n          \"A captivating western film about a forbidden love. featuring outstanding performances and breathtaking cinematography.\",\n          \"This thrilling action movie follows a small town. full of unexpected twists and turns. features spectacular action sequences and stunts.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"genre\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 22,\n        \"samples\": [\n          \"Romance\",\n          \"Sport\",\n          \"Western\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.2023180604448267,\n        \"min\": 1.8,\n        \"max\": 10.0,\n        \"num_unique_values\": 79,\n        \"samples\": [\n          4.7,\n          7.1,\n          6.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# Load movie data\n",
        "# If running in Google Colab and data file doesn't exist, download it from GitHub\n",
        "import os\n",
        "\n",
        "if not os.path.exists('data/movies.csv'):\n",
        "    print(\"Data file not found. Downloading from GitHub...\")\n",
        "    os.makedirs('data', exist_ok=True)\n",
        "    import urllib.request\n",
        "    url = 'https://raw.githubusercontent.com/samsung-ai-course/8th-9th-edition/main/Chapter%202%20-%20Natural%20Language%20Processing/Class%201%20%26%202%20-%20NLP%20and%20Search/data/movies.csv'\n",
        "    urllib.request.urlretrieve(url, 'data/movies.csv')\n",
        "    print(\"‚úì Data file downloaded successfully!\")\n",
        "\n",
        "df = pd.read_csv('data/movies.csv')\n",
        "print(f\"Loaded {len(df)} movies\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6QR-dkCrJ-y"
      },
      "source": [
        "## Exercise 3: TF-IDF from Scratch\n",
        "\n",
        "Implement TF-IDF calculation manually to understand how it works.\n",
        "\n",
        "**Prerequisites**: You should have completed Exercise 1 in Part 1 where you learned TF (Term Frequency) / Bag of Words.\n",
        "\n",
        "**Note**: This is labeled as Exercise 3 because it builds on Exercises 1-2 from Part 1.\n",
        "\n",
        "**In this exercise, you'll learn:**\n",
        "1. Calculate Inverse Document Frequency (IDF) - how rare a word is across all documents\n",
        "2. Calculate TF-IDF = TF √ó IDF - weighted word importance\n",
        "3. Build TF-IDF vectors from scratch\n",
        "\n",
        "**Key Point**: TF-IDF improves on simple BoW by weighting words by their importance!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "IL22GslRrJ-y",
        "outputId": "68479247-941b-42da-f1bf-dc59526c54e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing TF-IDF calculation:\n",
            "============================================================\n",
            "TF of 'natural' in doc 0: 0.3333333333333333\n",
            "IDF of 'natural': 0.4054651081081644\n",
            "TF-IDF of 'natural' in doc 0: 0.13515503603605478\n",
            "\n",
            "============================================================\n",
            "Testing More Examples:\n",
            "============================================================\n",
            "\n",
            "Term: 'natural'\n",
            "  Appears in documents: [0, 1]\n",
            "  Doc 0: TF=0.333, IDF=0.405, TF-IDF=0.135\n",
            "  Doc 1: TF=0.333, IDF=0.405, TF-IDF=0.135\n",
            "\n",
            "Term: 'learning'\n",
            "  Appears in documents: [1, 2]\n",
            "  Doc 1: TF=0.333, IDF=0.405, TF-IDF=0.135\n",
            "  Doc 2: TF=0.500, IDF=0.405, TF-IDF=0.203\n",
            "\n",
            "Term: 'processing'\n",
            "  Appears in documents: [0]\n",
            "  Doc 0: TF=0.333, IDF=1.099, TF-IDF=0.366\n",
            "\n",
            "Term: 'machine'\n",
            "  Appears in documents: [1]\n",
            "  Doc 1: TF=0.333, IDF=1.099, TF-IDF=0.366\n",
            "\n",
            "============================================================\n",
            "Key Insights:\n",
            "============================================================\n",
            "1. Common words (like 'learning', 'natural') have lower IDF (appear in multiple docs)\n",
            "2. Rare words (like 'machine', 'processing') have higher IDF (appear in few docs)\n",
            "3. TF-IDF = TF √ó IDF balances document-specific importance with global rarity\n",
            "4. High TF-IDF = word is frequent in document AND rare across corpus (very informative!)\n",
            "5. Notice how 'learning' appears in 2 docs - same IDF (global rarity) but different TF-IDF due to different TF (document frequency)!\n",
            "\n",
            "üí° Reference: See Learning Notebook Part 2, cells 8-9 for detailed TF-IDF explanation\n",
            "üí° Think about edge cases: What if document is empty? Term not in any doc?\n"
          ]
        }
      ],
      "source": [
        "def calculate_tf(term, document_tokens):\n",
        "    \"\"\"\n",
        "    Calculate Term Frequency: count(term) / total_terms\n",
        "\n",
        "    Note: This is from Part 1! You should have implemented this already.\n",
        "    If you haven't, complete it here first.\n",
        "\n",
        "    Args:\n",
        "        term (str): The word to count\n",
        "        document_tokens (list): List of tokens in the document\n",
        "\n",
        "    Returns:\n",
        "        float: Term frequency\n",
        "    \"\"\"\n",
        "    if len(document_tokens) == 0:\n",
        "        return 0.0\n",
        "    else:\n",
        "      times = document_tokens.count(term)\n",
        "      return times / len(document_tokens)\n",
        "\n",
        "def calculate_idf(term, all_documents_tokens):\n",
        "    \"\"\"\n",
        "    Calculate Inverse Document Frequency: log(total_docs / docs_containing_term)\n",
        "\n",
        "    IDF measures how rare/important a word is:\n",
        "    - High IDF = word appears in few documents (rare, informative)\n",
        "    - Low IDF = word appears in many documents (common, less informative)\n",
        "\n",
        "    Args:\n",
        "        term (str): The word\n",
        "        all_documents_tokens (list): List of documents, each is a list of tokens\n",
        "\n",
        "    Returns:\n",
        "        float: Inverse document frequency\n",
        "    \"\"\"\n",
        "    import math\n",
        "\n",
        "    total_docs = len(all_documents_tokens)\n",
        "\n",
        "    # Count how many documents contain the term\n",
        "    docs_with_term = sum(1 for doc in all_documents_tokens if term in doc)\n",
        "\n",
        "    # Handle edge case: term doesn't appear in any document\n",
        "    if docs_with_term == 0:\n",
        "        return 0.0\n",
        "\n",
        "    # Calculate log(total_docs / docs_with_term)\n",
        "    return math.log(total_docs / docs_with_term)\n",
        "\n",
        "def calculate_tfidf(term, document_tokens, all_documents_tokens):\n",
        "    \"\"\"\n",
        "    Calculate TF-IDF = TF √ó IDF\n",
        "\n",
        "    TF-IDF combines:\n",
        "    - TF: How important is the word in THIS document?\n",
        "    - IDF: How rare/important is the word across ALL documents?\n",
        "\n",
        "    High TF-IDF = word is frequent in this document AND rare across documents (very informative!)\n",
        "\n",
        "    Args:\n",
        "        term (str): The word\n",
        "        document_tokens (list): Tokens in current document\n",
        "        all_documents_tokens (list): All documents as lists of tokens\n",
        "\n",
        "    Returns:\n",
        "        float: TF-IDF score\n",
        "    \"\"\"\n",
        "    # Calculate TF and IDF, then multiply them\n",
        "    tf = calculate_tf(term, document_tokens)\n",
        "    idf = calculate_idf(term, all_documents_tokens)\n",
        "\n",
        "    return tf * idf\n",
        "\n",
        "# Test with simple example\n",
        "# Note: Updated so \"learning\" has different TF in different docs to show different TF-IDF values\n",
        "docs = [\n",
        "    [\"natural\", \"language\", \"processing\"],\n",
        "    [\"machine\", \"learning\", \"natural\"],           # \"learning\" appears 1/3 = 0.333\n",
        "    [\"deep\", \"learning\", \"learning\", \"language\"]  # \"learning\" appears 2/4 = 0.500 (different TF!)\n",
        "]\n",
        "\n",
        "print(\"Testing TF-IDF calculation:\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"TF of 'natural' in doc 0: {calculate_tf('natural', docs[0])}\")\n",
        "print(f\"IDF of 'natural': {calculate_idf('natural', docs)}\")\n",
        "print(f\"TF-IDF of 'natural' in doc 0: {calculate_tfidf('natural', docs[0], docs)}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Testing More Examples:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Test different words\n",
        "test_terms = ['natural', 'learning', 'processing', 'machine']\n",
        "for term in test_terms:\n",
        "    print(f\"\\nTerm: '{term}'\")\n",
        "    # Find which documents contain this term\n",
        "    doc_indices = [i for i, doc in enumerate(docs) if term in doc]\n",
        "    print(f\"  Appears in documents: {doc_indices}\")\n",
        "\n",
        "    for doc_idx in doc_indices:\n",
        "        tf = calculate_tf(term, docs[doc_idx])\n",
        "        idf = calculate_idf(term, docs)\n",
        "        tfidf = calculate_tfidf(term, docs[doc_idx], docs)\n",
        "        print(f\"  Doc {doc_idx}: TF={tf:.3f}, IDF={idf:.3f}, TF-IDF={tfidf:.3f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Key Insights:\")\n",
        "print(\"=\" * 60)\n",
        "print(\"1. Common words (like 'learning', 'natural') have lower IDF (appear in multiple docs)\")\n",
        "print(\"2. Rare words (like 'machine', 'processing') have higher IDF (appear in few docs)\")\n",
        "print(\"3. TF-IDF = TF √ó IDF balances document-specific importance with global rarity\")\n",
        "print(\"4. High TF-IDF = word is frequent in document AND rare across corpus (very informative!)\")\n",
        "print(\"5. Notice how 'learning' appears in 2 docs - same IDF (global rarity) but different TF-IDF due to different TF (document frequency)!\")\n",
        "\n",
        "print(\"\\nüí° Reference: See Learning Notebook Part 2, cells 8-9 for detailed TF-IDF explanation\")\n",
        "print(\"üí° Think about edge cases: What if document is empty? Term not in any doc?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggnw-n_7rJ-1"
      },
      "source": [
        "## Exercise 4: Build TF-IDF Vectors from Scratch\n",
        "\n",
        "After calculating individual TF-IDF scores, build complete TF-IDF vectors for documents.\n",
        "\n",
        "**Goal**: Create TF-IDF vectors (like BoW vectors but with TF-IDF scores instead of counts).\n",
        "\n",
        "**What you'll implement:**\n",
        "1. Build vocabulary from all documents\n",
        "2. For each document, calculate TF-IDF for each word in vocabulary\n",
        "3. Create a vector where each position corresponds to a word in vocabulary\n",
        "4. Return the TF-IDF vector\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Vap8rs0rJ-3",
        "outputId": "7a4085ee-40cb-4dd0-9471-61750070fe46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing TF-IDF Vector Creation:\n",
            "============================================================\n",
            "Vocabulary: ['deep', 'language', 'learning', 'machine', 'natural', 'processing']\n",
            "\n",
            "TF-IDF Matrix:\n",
            "Shape: 3 documents √ó 6 words\n",
            "\n",
            "Document 0: ['natural', 'language', 'processing']\n",
            "TF-IDF Vector: [0.0, 0.13515503603605478, 0.0, 0.0, 0.13515503603605478, 0.3662040962227032]\n",
            "\n",
            "Document 1: ['machine', 'learning', 'natural']\n",
            "TF-IDF Vector: [0.0, 0.0, 0.13515503603605478, 0.3662040962227032, 0.13515503603605478, 0.0]\n",
            "\n",
            "Document 2: ['deep', 'learning', 'language']\n",
            "TF-IDF Vector: [0.3662040962227032, 0.13515503603605478, 0.13515503603605478, 0.0, 0.0, 0.0]\n",
            "\n",
            "============================================================\n",
            "Comparison: BoW vs TF-IDF\n",
            "============================================================\n",
            "\n",
            "BoW vectors (word counts):\n",
            "Doc 0: [0, 1, 0, 0, 1, 1]\n",
            "Doc 1: [0, 0, 1, 1, 1, 0]\n",
            "Doc 2: [1, 1, 1, 0, 0, 0]\n",
            "\n",
            "TF-IDF vectors (weighted scores):\n",
            "Doc 0: [0.0, 0.135, 0.0, 0.0, 0.135, 0.366]\n",
            "Doc 1: [0.0, 0.0, 0.135, 0.366, 0.135, 0.0]\n",
            "Doc 2: [0.366, 0.135, 0.135, 0.0, 0.0, 0.0]\n",
            "\n",
            "üí° Key Difference:\n",
            "  - BoW: Simple counts (0, 1, 2, ...)\n",
            "  - TF-IDF: Weighted scores (0.0 to higher values)\n",
            "  - TF-IDF emphasizes rare, informative words more!\n"
          ]
        }
      ],
      "source": [
        "def create_tfidf_vector(document_tokens, vocabulary, all_documents_tokens):\n",
        "    \"\"\"\n",
        "    Create a TF-IDF vector for a document.\n",
        "\n",
        "    Similar to BoW vector, but uses TF-IDF scores instead of counts!\n",
        "\n",
        "    Args:\n",
        "        document_tokens: List of tokens in the document\n",
        "        vocabulary: List of all unique words in the corpus (sorted)\n",
        "        all_documents_tokens: List of all documents as lists of tokens\n",
        "\n",
        "    Returns:\n",
        "        list: TF-IDF vector where each element is the TF-IDF score for that word\n",
        "    \"\"\"\n",
        "    vector = []\n",
        "\n",
        "    # Loop through vocabulary and calculate TF-IDF for each word\n",
        "    for word in vocabulary:\n",
        "        # Calculate TF-IDF score for that word in this document\n",
        "        # If word doesn't appear in document, TF-IDF = 0 (handled by calculate_tfidf)\n",
        "        tfidf_score = calculate_tfidf(word, document_tokens, all_documents_tokens)\n",
        "        vector.append(tfidf_score)\n",
        "\n",
        "    return vector\n",
        "\n",
        "def create_tfidf_matrix(all_documents_tokens):\n",
        "    \"\"\"\n",
        "    Create a TF-IDF matrix for all documents.\n",
        "\n",
        "    Args:\n",
        "        all_documents_tokens: List of documents, each is a list of tokens\n",
        "\n",
        "    Returns:\n",
        "        tuple: (tfidf_matrix, vocabulary)\n",
        "            - tfidf_matrix: List of TF-IDF vectors (one per document)\n",
        "            - vocabulary: List of all unique words (sorted)\n",
        "    \"\"\"\n",
        "    # Step 1 - Build vocabulary from all documents\n",
        "    # Build vocabulary\n",
        "    all_words = set()\n",
        "    for doc_tokens in all_documents_tokens:\n",
        "        all_words.update(doc_tokens)\n",
        "    vocabulary = sorted(list(all_words))\n",
        "\n",
        "    # Step 2 - For each document, create TF-IDF vector\n",
        "    matrix = []\n",
        "    for doc_tokens in all_documents_tokens:\n",
        "        vector = create_tfidf_vector(doc_tokens, vocabulary, all_documents_tokens)\n",
        "        matrix.append(vector)\n",
        "\n",
        "    # Step 3 - Return matrix and vocabulary\n",
        "    return matrix, vocabulary\n",
        "\n",
        "# Test with simple example\n",
        "test_docs = [\n",
        "    [\"natural\", \"language\", \"processing\"],\n",
        "    [\"machine\", \"learning\", \"natural\"],\n",
        "    [\"deep\", \"learning\", \"language\"]\n",
        "]\n",
        "\n",
        "print(\"Testing TF-IDF Vector Creation:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "tfidf_matrix, vocab = create_tfidf_matrix(test_docs)\n",
        "\n",
        "print(f\"Vocabulary: {vocab}\")\n",
        "print(f\"\\nTF-IDF Matrix:\")\n",
        "print(f\"Shape: {len(tfidf_matrix)} documents √ó {len(vocab)} words\")\n",
        "\n",
        "for i, doc_vector in enumerate(tfidf_matrix):\n",
        "    print(f\"\\nDocument {i}: {test_docs[i]}\")\n",
        "    print(f\"TF-IDF Vector: {doc_vector}\")\n",
        "\n",
        "# Compare with BoW (from Part 1)\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Comparison: BoW vs TF-IDF\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Simple BoW for comparison\n",
        "def create_bow_vector_simple(doc_tokens, vocab):\n",
        "    word_counts = Counter(doc_tokens)\n",
        "    return [word_counts.get(word, 0) for word in vocab]\n",
        "\n",
        "print(\"\\nBoW vectors (word counts):\")\n",
        "for i, doc_tokens in enumerate(test_docs):\n",
        "    bow_vec = create_bow_vector_simple(doc_tokens, vocab)\n",
        "    print(f\"Doc {i}: {bow_vec}\")\n",
        "\n",
        "print(\"\\nTF-IDF vectors (weighted scores):\")\n",
        "for i, doc_vector in enumerate(tfidf_matrix):\n",
        "    print(f\"Doc {i}: {[round(x, 3) for x in doc_vector]}\")\n",
        "\n",
        "print(\"\\nüí° Key Difference:\")\n",
        "print(\"  - BoW: Simple counts (0, 1, 2, ...)\")\n",
        "print(\"  - TF-IDF: Weighted scores (0.0 to higher values)\")\n",
        "print(\"  - TF-IDF emphasizes rare, informative words more!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtF_DWuorJ-6"
      },
      "source": [
        "## Exercise 5: Similarity-Based Search with TF-IDF\n",
        "\n",
        "Implement similarity-based search using TF-IDF vectors and cosine similarity.\n",
        "\n",
        "**Prerequisites**: You need TF-IDF vectors! Use scikit-learn's `TfidfVectorizer` (or build from scratch using Exercise 3 & 4).\n",
        "\n",
        "**What you'll implement:**\n",
        "1. Convert query to TF-IDF vector\n",
        "2. Calculate cosine similarity between query and all documents\n",
        "3. Return top-k most similar documents\n",
        "\n",
        "**Note**: This is often called \"semantic search\" but TF-IDF is still fundamentally keyword-based. True semantic search (understanding synonyms and meaning) requires embeddings (Class 3)!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8vdkM5qrrJ-7",
        "outputId": "b4b0fbbb-d89a-4d10-afa6-fb0f75fcecd6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating TF-IDF vectors...\n",
            "‚úì Created TF-IDF matrix: (10000, 100)\n",
            "\n",
            "======================================================================\n",
            "Testing Similarity Search:\n",
            "======================================================================\n",
            "\n",
            "Query: 'space adventure exploration'\n",
            "\n",
            "Top Results:\n",
            "            title  similarity\n",
            "Under Point Rises    0.688765\n",
            "  Out of Ice Tale    0.649141\n",
            "      Wind of Ice    0.599094\n",
            " Guardian of Love    0.593995\n",
            "      Dream: Line    0.554876\n",
            "\n",
            "‚úÖ Success! Your search function is working.\n",
            "\n",
            "üí° Key Points:\n",
            "  - Cosine similarity measures the angle between vectors\n",
            "  - Range: -1 to 1 (but for TF-IDF, usually 0 to 1)\n",
            "  - Higher similarity = more similar documents\n",
            "  - Similarity search ranks by relevance (better than keyword search!)\n",
            "\n",
            "üí° Reference: See Learning Notebook Part 2, cell 11 for working example\n"
          ]
        }
      ],
      "source": [
        "def cosine_similarity_manual(vec1, vec2):\n",
        "    \"\"\"\n",
        "    Calculate cosine similarity between two vectors manually.\n",
        "\n",
        "    Cosine Similarity = (A ¬∑ B) / (||A|| √ó ||B||)\n",
        "    - A ¬∑ B = dot product\n",
        "    - ||A|| = magnitude (L2 norm) of vector A\n",
        "\n",
        "    Args:\n",
        "        vec1: First vector (list or array)\n",
        "        vec2: Second vector (list or array)\n",
        "\n",
        "    Returns:\n",
        "        float: Cosine similarity (range: -1 to 1, but for TF-IDF usually 0 to 1)\n",
        "    \"\"\"\n",
        "    import numpy as np\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    vec1 = np.array(vec1)\n",
        "    vec2 = np.array(vec2)\n",
        "\n",
        "    # Calculate dot product (A ¬∑ B)\n",
        "    dot_product = np.dot(vec1, vec2)\n",
        "\n",
        "    # Calculate magnitudes (||A|| and ||B||)\n",
        "    magnitude1 = np.linalg.norm(vec1)\n",
        "    magnitude2 = np.linalg.norm(vec2)\n",
        "\n",
        "    # Handle division by zero if both vectors are zero\n",
        "    if magnitude1 == 0 or magnitude2 == 0:\n",
        "        return 0.0\n",
        "\n",
        "    # Return cosine similarity = dot_product / (magnitude1 * magnitude2)\n",
        "    return dot_product / (magnitude1 * magnitude2)\n",
        "\n",
        "def search_tfidf(query, vectorizer, tfidf_vectors, df, top_k=5):\n",
        "    \"\"\"\n",
        "    Similarity-based search using TF-IDF and cosine similarity.\n",
        "\n",
        "    Steps:\n",
        "    1. Convert query to TF-IDF vector using the same vectorizer\n",
        "    2. Calculate cosine similarity with all document vectors\n",
        "    3. Get top_k most similar documents\n",
        "    4. Return results as DataFrame\n",
        "\n",
        "    Args:\n",
        "        query: Search query string\n",
        "        vectorizer: Fitted TfidfVectorizer\n",
        "        tfidf_vectors: TF-IDF matrix for all documents (sparse matrix)\n",
        "        df: DataFrame with movie data\n",
        "        top_k: Number of results to return\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with search results (title, similarity, description)\n",
        "    \"\"\"\n",
        "    # Step 1 - Convert query to TF-IDF vector\n",
        "    # Use vectorizer.transform([query]), NOT fit_transform()\n",
        "    # Why? Because vectorizer is already fitted on the corpus!\n",
        "    query_vector = vectorizer.transform([query])\n",
        "\n",
        "    # Step 2 - Calculate cosine similarity with all documents\n",
        "    # Use cosine_similarity from sklearn\n",
        "    # Remember to get the first row [0] since query_vector is 1xN\n",
        "    similarities = cosine_similarity(query_vector, tfidf_vectors)[0]\n",
        "\n",
        "    # Step 3 - Get indices of top_k most similar documents\n",
        "    # Use argsort() - it returns indices in ascending order\n",
        "    # You want descending (highest similarity first), so reverse it!\n",
        "    top_indices = similarities.argsort()[-top_k:][::-1]\n",
        "\n",
        "    # Step 4 - Build results DataFrame with movie_id, title, similarity, description\n",
        "    results = []\n",
        "    for idx in top_indices:\n",
        "        results.append({\n",
        "            'movie_id': df.iloc[idx]['movie_id'],\n",
        "            'title': df.iloc[idx]['title'],\n",
        "            'similarity': similarities[idx],\n",
        "            'description': df.iloc[idx]['description']\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# First, create TF-IDF vectors for the movie corpus\n",
        "print(\"Creating TF-IDF vectors...\")\n",
        "vectorizer = TfidfVectorizer(max_features=100, stop_words='english', lowercase=True)\n",
        "tfidf_vectors = vectorizer.fit_transform(df['description'])\n",
        "print(f\"‚úì Created TF-IDF matrix: {tfidf_vectors.shape}\")\n",
        "\n",
        "# Test your search function\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"Testing Similarity Search:\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "test_query = \"space adventure exploration\"\n",
        "print(f\"\\nQuery: '{test_query}'\")\n",
        "\n",
        "results = search_tfidf(test_query, vectorizer, tfidf_vectors, df, top_k=5)\n",
        "\n",
        "if len(results) > 0:\n",
        "    print(\"\\nTop Results:\")\n",
        "    print(results[['title', 'similarity']].to_string(index=False))\n",
        "    print(\"\\n‚úÖ Success! Your search function is working.\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è  Results empty - implement the function first!\")\n",
        "\n",
        "print(\"\\nüí° Key Points:\")\n",
        "print(\"  - Cosine similarity measures the angle between vectors\")\n",
        "print(\"  - Range: -1 to 1 (but for TF-IDF, usually 0 to 1)\")\n",
        "print(\"  - Higher similarity = more similar documents\")\n",
        "print(\"  - Similarity search ranks by relevance (better than keyword search!)\")\n",
        "\n",
        "print(\"\\nüí° Reference: See Learning Notebook Part 2, cell 11 for working example\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-LZKiZe1rJ-9",
        "outputId": "c771d522-b674-4365-9d0d-7c7e46ddac79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "Testing Euclidean Distance Search:\n",
            "======================================================================\n",
            "\n",
            "Query: 'space adventure exploration'\n",
            "\n",
            "Top Results (Euclidean Distance):\n",
            "            title  distance\n",
            "Under Point Rises  0.788968\n",
            "  Out of Ice Tale  0.837686\n",
            "      Wind of Ice  0.895440\n",
            " Guardian of Love  0.901116\n",
            "      Dream: Line  0.943530\n",
            "\n",
            "üí° Remember: Smaller distance = more similar!\n",
            "\n",
            "======================================================================\n",
            "Comparing Cosine vs Euclidean:\n",
            "======================================================================\n",
            "\n",
            "Cosine Similarity Results:\n",
            "            title  similarity\n",
            "Under Point Rises    0.688765\n",
            "  Out of Ice Tale    0.649141\n",
            "      Wind of Ice    0.599094\n",
            " Guardian of Love    0.593995\n",
            "      Dream: Line    0.554876\n",
            "\n",
            "Euclidean Distance Results:\n",
            "            title  distance\n",
            "Under Point Rises  0.788968\n",
            "  Out of Ice Tale  0.837686\n",
            "      Wind of Ice  0.895440\n",
            " Guardian of Love  0.901116\n",
            "      Dream: Line  0.943530\n",
            "\n",
            "üìä Overlap: 5/5 movies appear in both top-5 lists\n",
            "   Common movies: Dream: Line, Out of Ice Tale, Guardian of Love...\n",
            "\n",
            "üí° Key Observations:\n",
            "  - Cosine: Measures direction/pattern similarity\n",
            "  - Euclidean: Measures absolute distance in space\n",
            "  - For TF-IDF text search, cosine is usually better!\n",
            "\n",
            "üí° Reference: See Learning Notebook Part 2 for Cosine vs Euclidean comparison\n"
          ]
        }
      ],
      "source": [
        "def euclidean_distance_manual(vec1, vec2):\n",
        "    \"\"\"\n",
        "    Calculate Euclidean distance between two vectors manually.\n",
        "\n",
        "    Euclidean Distance = ‚àö(Œ£(a_i - b_i)¬≤)\n",
        "    - Sum of squared differences\n",
        "    - Square root of the sum\n",
        "\n",
        "    Args:\n",
        "        vec1: First vector (list or array)\n",
        "        vec2: Second vector (list or array)\n",
        "\n",
        "    Returns:\n",
        "        float: Euclidean distance (range: 0 to ‚àû, where 0 = identical)\n",
        "    \"\"\"\n",
        "    import numpy as np\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    vec1 = np.array(vec1)\n",
        "    vec2 = np.array(vec2)\n",
        "\n",
        "    # Calculate Euclidean distance\n",
        "    # Formula is ‚àö(Œ£(a_i - b_i)¬≤)\n",
        "    diff = vec1 - vec2\n",
        "    squared_diff = diff ** 2\n",
        "    sum_squared = np.sum(squared_diff)\n",
        "    distance = np.sqrt(sum_squared)\n",
        "\n",
        "    return distance\n",
        "\n",
        "def search_euclidean(query, vectorizer, tfidf_vectors, df, top_k=5):\n",
        "    \"\"\"\n",
        "    Similarity-based search using TF-IDF and Euclidean distance.\n",
        "\n",
        "    Steps:\n",
        "    1. Convert query to TF-IDF vector\n",
        "    2. Calculate Euclidean distance with all documents\n",
        "    3. Get top_k CLOSEST documents (smaller distance = more similar!)\n",
        "    4. Return results as DataFrame\n",
        "\n",
        "    Args:\n",
        "        query: Search query string\n",
        "        vectorizer: Fitted TfidfVectorizer\n",
        "        tfidf_vectors: TF-IDF matrix for all documents\n",
        "        df: DataFrame with movie data\n",
        "        top_k: Number of results to return\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with search results (title, distance, description)\n",
        "    \"\"\"\n",
        "    from sklearn.metrics.pairwise import euclidean_distances\n",
        "\n",
        "    # Step 1 - Convert query to TF-IDF vector\n",
        "    # Similar to Exercise 5, use vectorizer.transform()\n",
        "    query_vector = vectorizer.transform([query])\n",
        "\n",
        "    # Step 2 - Calculate Euclidean distance with all documents\n",
        "    # Use euclidean_distances from sklearn (or your manual function)\n",
        "    distances = euclidean_distances(query_vector, tfidf_vectors)[0]\n",
        "\n",
        "    # Step 3 - Get indices of top_k SMALLEST distances\n",
        "    # argsort() returns indices in ascending order - perfect for Euclidean!\n",
        "    # Smaller distance = more similar\n",
        "    top_indices = distances.argsort()[:top_k]\n",
        "\n",
        "    # Step 4 - Build results DataFrame with movie_id, title, distance, description\n",
        "    results = []\n",
        "    for idx in top_indices:\n",
        "        results.append({\n",
        "            'movie_id': df.iloc[idx]['movie_id'],\n",
        "            'title': df.iloc[idx]['title'],\n",
        "            'distance': distances[idx],\n",
        "            'description': df.iloc[idx]['description']\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# Test your Euclidean distance search function\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"Testing Euclidean Distance Search:\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "test_query = \"space adventure exploration\"\n",
        "print(f\"\\nQuery: '{test_query}'\")\n",
        "\n",
        "results_euclidean = search_euclidean(test_query, vectorizer, tfidf_vectors, df, top_k=5)\n",
        "\n",
        "if len(results_euclidean) > 0:\n",
        "    print(\"\\nTop Results (Euclidean Distance):\")\n",
        "    print(results_euclidean[['title', 'distance']].to_string(index=False))\n",
        "    print(\"\\nüí° Remember: Smaller distance = more similar!\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è  Results empty - implement the function first!\")\n",
        "\n",
        "# Compare with cosine similarity results\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"Comparing Cosine vs Euclidean:\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "results_cosine = search_tfidf(test_query, vectorizer, tfidf_vectors, df, top_k=5)\n",
        "\n",
        "if len(results_cosine) > 0 and len(results_euclidean) > 0:\n",
        "    print(\"\\nCosine Similarity Results:\")\n",
        "    print(results_cosine[['title', 'similarity']].to_string(index=False))\n",
        "\n",
        "    print(\"\\nEuclidean Distance Results:\")\n",
        "    print(results_euclidean[['title', 'distance']].to_string(index=False))\n",
        "\n",
        "    # Check overlap\n",
        "    cosine_titles = set(results_cosine['title'])\n",
        "    euclidean_titles = set(results_euclidean['title'])\n",
        "    overlap = cosine_titles.intersection(euclidean_titles)\n",
        "\n",
        "    print(f\"\\nüìä Overlap: {len(overlap)}/5 movies appear in both top-5 lists\")\n",
        "    if overlap:\n",
        "        print(f\"   Common movies: {', '.join(list(overlap)[:3])}...\")\n",
        "\n",
        "    print(\"\\nüí° Key Observations:\")\n",
        "    print(\"  - Cosine: Measures direction/pattern similarity\")\n",
        "    print(\"  - Euclidean: Measures absolute distance in space\")\n",
        "    print(\"  - For TF-IDF text search, cosine is usually better!\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è  Implement both search functions to see the comparison!\")\n",
        "\n",
        "print(\"\\nüí° Reference: See Learning Notebook Part 2 for Cosine vs Euclidean comparison\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neVngFv0rJ--"
      },
      "source": [
        "## Exercise 5b: Euclidean Distance Search (Bonus)\n",
        "\n",
        "Now implement the same search functionality but using **Euclidean Distance** instead of Cosine Similarity!\n",
        "\n",
        "**Goal**: Understand the difference between cosine and Euclidean distance metrics.\n",
        "\n",
        "**Key Differences**:\n",
        "- **Cosine Similarity**: Measures direction/angle (ignores magnitude) - Range: -1 to 1\n",
        "- **Euclidean Distance**: Measures absolute distance (considers magnitude) - Range: 0 to ‚àû\n",
        "\n",
        "**For search results**:\n",
        "- **Cosine**: Higher similarity = more similar (sort descending)\n",
        "- **Euclidean**: Smaller distance = more similar (sort ascending)\n",
        "\n",
        "**Your Task**: Implement `search_euclidean()` function that:\n",
        "1. Converts query to TF-IDF vector\n",
        "2. Calculates Euclidean distance to all documents\n",
        "3. Returns documents with **smallest distance** (most similar)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qukBJLkDrJ-_"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92uYFanYrJ-_"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "adlpDx1ArJ-_"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WCi459SqrJ-_"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "j8fwWavcrJ_A"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KL7dhmjprJ_A"
      },
      "source": [
        "## Exercise 6: Hybrid Search\n",
        "\n",
        "**Goal**: Combine TF-IDF similarity search with keyword matching for the best of both worlds!\n",
        "\n",
        "**What you'll implement:**\n",
        "1. Get TF-IDF similarity scores\n",
        "2. Get keyword match scores\n",
        "3. Combine scores using weighted sum\n",
        "4. Add boost for exact keyword matches\n",
        "5. Return top-k results sorted by combined score\n",
        "\n",
        "**Key Benefits:**\n",
        "- Precision from keyword matching (exact matches)\n",
        "- Recall from TF-IDF (related content)\n",
        "- Most robust approach for production systems!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "hjjKnQFKrJ_A"
      },
      "outputs": [],
      "source": [
        "# Hybrid Search Implementation - Combining TF-IDF + Keyword Matching\n",
        "def hybrid_search(query, vectorizer, tfidf_vectors, df, top_k=5, keyword_weight=0.3, boost_factor=0.2):\n",
        "    \"\"\"\n",
        "    Hybrid search combining TF-IDF similarity and keyword matching\n",
        "\n",
        "    Args:\n",
        "        query: Search query string\n",
        "        vectorizer: Fitted TF-IDF vectorizer\n",
        "        tfidf_vectors: TF-IDF vectors for all documents\n",
        "        df: DataFrame with movie data\n",
        "        top_k: Number of results to return\n",
        "        keyword_weight: Weight for keyword matching (0-1). 0.3 = 30% keyword, 70% TF-IDF\n",
        "        boost_factor: Additional boost for exact keyword matches (added to TF-IDF score)\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with search results sorted by combined score\n",
        "    \"\"\"\n",
        "    import re\n",
        "\n",
        "    # Step 1: Get TF-IDF similarity scores\n",
        "    # Convert query to TF-IDF vector and calculate cosine similarity with all documents\n",
        "    query_vector = vectorizer.transform([query])\n",
        "    tfidf_similarities = cosine_similarity(query_vector, tfidf_vectors)[0]\n",
        "\n",
        "    # Step 2: Get keyword match scores\n",
        "    # Extract words from query and count how many appear in each document\n",
        "    query_words = set(re.findall(r'\\w+', query.lower()))  # Extract words from query\n",
        "    keyword_scores = []\n",
        "    keyword_match_counts = []\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "        text = str(row['description']).lower()\n",
        "        text_words = set(re.findall(r'\\w+', text))\n",
        "\n",
        "        # Count how many query words appear in document using set intersection\n",
        "        matches = query_words.intersection(text_words)\n",
        "        match_count = len(matches)\n",
        "\n",
        "        # Calculate normalized match ratio (0 to 1)\n",
        "        match_ratio = match_count / len(query_words) if len(query_words) > 0 else 0\n",
        "\n",
        "        keyword_scores.append(match_ratio)  # Normalized: 0 to 1\n",
        "        keyword_match_counts.append(match_count)  # Raw count\n",
        "\n",
        "    keyword_scores = np.array(keyword_scores)\n",
        "    keyword_match_counts = np.array(keyword_match_counts)\n",
        "\n",
        "    # Step 3: Combine scores using weighted sum\n",
        "    # Normalize TF-IDF scores to 0-1 range using min-max normalization\n",
        "    # This ensures both keyword and TF-IDF scores are on the same scale\n",
        "    tfidf_normalized = (tfidf_similarities - tfidf_similarities.min()) / (tfidf_similarities.max() - tfidf_similarities.min() + 1e-8)\n",
        "\n",
        "    # TODO: Combine scores using weighted sum\n",
        "    # Formula: combined = (keyword_weight √ó keyword_score) + ((1 - keyword_weight) √ó tfidf_score)\n",
        "    # Example: If keyword_weight=0.3, then 30% keyword + 70% TF-IDF\n",
        "    # Hint: Use numpy array operations for element-wise multiplication\n",
        "    combined_scores = (keyword_weight * keyword_scores) + ((1 - keyword_weight) * tfidf_normalized)\n",
        "\n",
        "    # Step 4: Add boost for exact keyword matches\n",
        "    # Documents with more keyword matches get an additional boost\n",
        "    # This helps prioritize exact matches while still benefiting from TF-IDF ranking\n",
        "    max_matches = keyword_match_counts.max() if keyword_match_counts.max() > 0 else 1\n",
        "    keyword_boost = (keyword_match_counts / max_matches) * boost_factor\n",
        "    final_scores = combined_scores + keyword_boost\n",
        "\n",
        "    # Step 5: Get top_k results\n",
        "    # Sort by final scores (descending) and get top_k indices\n",
        "    top_indices = final_scores.argsort()[-top_k:][::-1]\n",
        "\n",
        "    # Build results DataFrame with all relevant information\n",
        "    results = []\n",
        "    for idx in top_indices:\n",
        "        results.append({\n",
        "            'movie_id': df.iloc[idx]['movie_id'],\n",
        "            'title': df.iloc[idx]['title'],\n",
        "            'final_score': final_scores[idx],\n",
        "            'tfidf_score': tfidf_similarities[idx],\n",
        "            'keyword_score': keyword_scores[idx],\n",
        "            'keyword_matches': keyword_match_counts[idx],\n",
        "            'description': df.iloc[idx]['description']\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(results)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGVf4OmOrJ_B"
      },
      "source": [
        "## Exercise 7: Compare Search Methods\n",
        "\n",
        "**Goal**: Compare keyword search, TF-IDF search, and hybrid search side-by-side!\n",
        "\n",
        "**Your Task**: Test all three search methods on the same query and observe the differences.\n",
        "\n",
        "**This helps you understand:**\n",
        "- When to use each method\n",
        "- How different approaches affect results\n",
        "- Why hybrid search is often the best choice\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "BApcP1UtrJ_C",
        "outputId": "5e667c21-3db4-4056-9bf2-5ebfddf094cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "COMPARISON: Search Results for Query 'space adventure aliens'\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "1. KEYWORD SEARCH (Exact Word Matching)\n",
            "================================================================================\n",
            "              title  match_count\n",
            "Through Hope Reborn            2\n",
            "      Hope of Dream            2\n",
            "       Out of Peace            2\n",
            "     The Gate Redux            2\n",
            "     Shadow of Game            2\n",
            "\n",
            "‚úÖ Finds documents with exact word matches\n",
            "‚ùå No ranking beyond match count\n",
            "‚ùå Misses related content without exact words\n",
            "\n",
            "================================================================================\n",
            "2. TF-IDF SIMILARITY SEARCH\n",
            "================================================================================\n",
            "            title  similarity\n",
            "Under Point Rises    0.688765\n",
            "  Out of Ice Tale    0.649141\n",
            "      Wind of Ice    0.599094\n",
            " Guardian of Love    0.593995\n",
            "      Dream: Line    0.554876\n",
            "\n",
            "‚úÖ Ranks by importance (TF-IDF weighted)\n",
            "‚úÖ Finds related content even without exact matches\n",
            "‚ö†Ô∏è  Might rank exact matches lower if they have low TF-IDF\n",
            "\n",
            "================================================================================\n",
            "3. HYBRID SEARCH (TF-IDF + Keyword Matching)\n",
            "================================================================================\n",
            "                  title  final_score\n",
            "      Under Point Rises     1.100000\n",
            "        Out of Ice Tale     1.059730\n",
            "       Guardian of Love     1.003685\n",
            "            Dream: Line     0.963927\n",
            "Under Peace Revolutions     0.958194\n",
            "\n",
            "‚úÖ Combines best of both: keyword precision + TF-IDF recall\n",
            "‚úÖ Boosts exact matches while still finding related content\n",
            "‚úÖ Most flexible and robust approach\n",
            "\n",
            "================================================================================\n",
            "SUMMARY: When to Use Each Method\n",
            "================================================================================\n",
            "\n",
            "Keyword Search:\n",
            "  - ‚úÖ Fast and simple\n",
            "  - ‚úÖ Good for exact phrase matching\n",
            "  - ‚ùå Too rigid, misses related content\n",
            "  - Use when: You need exact matches only\n",
            "\n",
            "TF-IDF Search:\n",
            "  - ‚úÖ Better ranking by importance\n",
            "  - ‚úÖ Finds related content\n",
            "  - ‚ö†Ô∏è  Might miss exact matches\n",
            "  - Use when: You want semantic-like matching (but still keyword-based)\n",
            "\n",
            "Hybrid Search:\n",
            "  - ‚úÖ Best of both worlds\n",
            "  - ‚úÖ Precision from keywords + recall from TF-IDF\n",
            "  - ‚úÖ Most robust for production systems\n",
            "  - Use when: Building a real search system (recommended!)\n",
            "\n",
            "üí° For our movie search system, hybrid search gives the best results!\n",
            "üí° Try different queries and see how each method performs!\n"
          ]
        }
      ],
      "source": [
        "# TODO: Compare all three search methods on the same query\n",
        "\n",
        "def simple_keyword_search_compare(query, df, top_k=5):\n",
        "    \"\"\"\n",
        "    Simple keyword search for comparison (from Part 1).\n",
        "    Finds documents containing query words.\n",
        "    \"\"\"\n",
        "    import re\n",
        "    query_words = set(re.findall(r'\\w+', query.lower()))\n",
        "    results = []\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "        text = str(row['description']).lower()\n",
        "        text_words = set(re.findall(r'\\w+', text))\n",
        "        matches = query_words.intersection(text_words)\n",
        "        match_count = len(matches)\n",
        "\n",
        "        if match_count > 0:\n",
        "            results.append({\n",
        "                'movie_id': row['movie_id'],\n",
        "                'title': row['title'],\n",
        "                'match_count': match_count,\n",
        "                'description': row['description']\n",
        "            })\n",
        "\n",
        "    results_df = pd.DataFrame(results)\n",
        "    if len(results_df) > 0:\n",
        "        results_df = results_df.sort_values('match_count', ascending=False).head(top_k)\n",
        "    return results_df\n",
        "\n",
        "# Test query\n",
        "test_query = \"space adventure aliens\"\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(f\"COMPARISON: Search Results for Query '{test_query}'\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Method 1: Keyword Search\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"1. KEYWORD SEARCH (Exact Word Matching)\")\n",
        "print(\"=\" * 80)\n",
        "keyword_results = simple_keyword_search_compare(test_query, df, top_k=5)\n",
        "if len(keyword_results) > 0:\n",
        "    print(keyword_results[['title', 'match_count']].to_string(index=False))\n",
        "    print(\"\\n‚úÖ Finds documents with exact word matches\")\n",
        "    print(\"‚ùå No ranking beyond match count\")\n",
        "    print(\"‚ùå Misses related content without exact words\")\n",
        "else:\n",
        "    print(\"No results found\")\n",
        "\n",
        "# Method 2: TF-IDF Search\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"2. TF-IDF SIMILARITY SEARCH\")\n",
        "print(\"=\" * 80)\n",
        "tfidf_results = search_tfidf(test_query, vectorizer, tfidf_vectors, df, top_k=5)\n",
        "if len(tfidf_results) > 0:\n",
        "    print(tfidf_results[['title', 'similarity']].to_string(index=False))\n",
        "    print(\"\\n‚úÖ Ranks by importance (TF-IDF weighted)\")\n",
        "    print(\"‚úÖ Finds related content even without exact matches\")\n",
        "    print(\"‚ö†Ô∏è  Might rank exact matches lower if they have low TF-IDF\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Implement search_tfidf first!\")\n",
        "\n",
        "# Method 3: Hybrid Search\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"3. HYBRID SEARCH (TF-IDF + Keyword Matching)\")\n",
        "print(\"=\" * 80)\n",
        "hybrid_results = hybrid_search(test_query, vectorizer, tfidf_vectors, df, top_k=5,\n",
        "                               keyword_weight=0.3, boost_factor=0.2)\n",
        "if len(hybrid_results) > 0:\n",
        "    print(hybrid_results[['title', 'final_score']].head(5).to_string(index=False))\n",
        "    print(\"\\n‚úÖ Combines best of both: keyword precision + TF-IDF recall\")\n",
        "    print(\"‚úÖ Boosts exact matches while still finding related content\")\n",
        "    print(\"‚úÖ Most flexible and robust approach\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Implement hybrid_search first!\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"SUMMARY: When to Use Each Method\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\"\"\n",
        "Keyword Search:\n",
        "  - ‚úÖ Fast and simple\n",
        "  - ‚úÖ Good for exact phrase matching\n",
        "  - ‚ùå Too rigid, misses related content\n",
        "  - Use when: You need exact matches only\n",
        "\n",
        "TF-IDF Search:\n",
        "  - ‚úÖ Better ranking by importance\n",
        "  - ‚úÖ Finds related content\n",
        "  - ‚ö†Ô∏è  Might miss exact matches\n",
        "  - Use when: You want semantic-like matching (but still keyword-based)\n",
        "\n",
        "Hybrid Search:\n",
        "  - ‚úÖ Best of both worlds\n",
        "  - ‚úÖ Precision from keywords + recall from TF-IDF\n",
        "  - ‚úÖ Most robust for production systems\n",
        "  - Use when: Building a real search system (recommended!)\n",
        "\"\"\")\n",
        "\n",
        "print(\"üí° For our movie search system, hybrid search gives the best results!\")\n",
        "print(\"üí° Try different queries and see how each method performs!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISarHX0UrJ_C"
      },
      "source": [
        "## Bonus Exercise: Evaluate and Compare Search Methods\n",
        "\n",
        "**Goal**: Use your metrics to objectively compare different search approaches!\n",
        "\n",
        "**Your task:**\n",
        "1. Create a function that runs a search query and returns top-K results\n",
        "2. Define ground truth (relevant movie IDs) for a test query\n",
        "3. Run the same query through:\n",
        "   - Keyword search\n",
        "   - TF-IDF similarity search\n",
        "   - Hybrid search (with different parameters)\n",
        "4. Calculate Precision, Recall, NDCG, and MRR for each\n",
        "5. Determine which approach works best!\n",
        "\n",
        "**This is what real search engineers do** - use metrics to guide improvements!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "p3spgjGjrJ_E",
        "outputId": "c3715fac-e76e-4360-8a74-afe633801fa0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "Comparing Search Methods\n",
            "======================================================================\n",
            "\n",
            "üí° This is how you tune search systems in production!\n",
            "   Try different parameters, measure with metrics, pick the best!\n",
            "\n",
            "üìö Reference: Learning Notebook Part 2 for complete examples\n"
          ]
        }
      ],
      "source": [
        "# Bonus Exercise: Compare Search Methods with Metrics\n",
        "\n",
        "def evaluate_search_method(search_function, query, relevant_ids, k=10):\n",
        "    \"\"\"\n",
        "    Evaluate a search method using multiple metrics.\n",
        "\n",
        "    Args:\n",
        "        search_function: Function that takes query and returns ranked results\n",
        "        query: Search query string\n",
        "        relevant_ids: Ground truth relevant IDs\n",
        "        k: Number of top results to evaluate\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary of metric scores\n",
        "    \"\"\"\n",
        "    # TODO: Call search_function to get results\n",
        "    # TODO: Calculate Precision@K, Recall@K, NDCG@K, RR\n",
        "    # TODO: Return as dictionary\n",
        "\n",
        "    # Hint: Structure of return value:\n",
        "    # return {\n",
        "    #     'precision@k': ...,\n",
        "    #     'recall@k': ...,\n",
        "    #     'ndcg@k': ...,\n",
        "    #     'mrr': ...\n",
        "    # }\n",
        "\n",
        "    pass  # Remove this and implement\n",
        "\n",
        "# Example usage (after implementing):\n",
        "print(\"=\"*70)\n",
        "print(\"Comparing Search Methods\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "query = \"space adventure exploration\"\n",
        "\n",
        "# You would need to define:\n",
        "# 1. Ground truth relevant movies for this query\n",
        "# 2. Functions for each search method\n",
        "\n",
        "# Example:\n",
        "# ground_truth = [10, 25, 42, 67, 89, 103, 156]  # Movies actually about space adventure\n",
        "#\n",
        "# metrics_keyword = evaluate_search_method(keyword_search, query, ground_truth)\n",
        "# metrics_tfidf = evaluate_search_method(tfidf_search, query, ground_truth)\n",
        "# metrics_hybrid = evaluate_search_method(hybrid_search, query, ground_truth)\n",
        "#\n",
        "# # Compare results\n",
        "# print(f\"\\nKeyword Search:  P={metrics_keyword['precision@k']:.3f} NDCG={metrics_keyword['ndcg@k']:.3f}\")\n",
        "# print(f\"TF-IDF Search:   P={metrics_tfidf['precision@k']:.3f} NDCG={metrics_tfidf['ndcg@k']:.3f}\")\n",
        "# print(f\"Hybrid Search:   P={metrics_hybrid['precision@k']:.3f} NDCG={metrics_hybrid['ndcg@k']:.3f}\")\n",
        "\n",
        "print(\"\\nüí° This is how you tune search systems in production!\")\n",
        "print(\"   Try different parameters, measure with metrics, pick the best!\")\n",
        "print(\"\\nüìö Reference: Learning Notebook Part 2 for complete examples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxYAghiLrJ_E"
      },
      "source": [
        "## Exercise 5: Implement Precision@K and Recall@K\n",
        "\n",
        "**Goal**: Implement the two most fundamental search evaluation metrics from scratch!\n",
        "\n",
        "**Prerequisites**: Complete Exercise 3 (similarity search) first - you'll need search results to evaluate.\n",
        "\n",
        "**What you'll implement:**\n",
        "1. `precision_at_k()` - Calculate what % of top-K results are relevant\n",
        "2. `recall_at_k()` - Calculate what % of all relevant docs are found in top-K\n",
        "3. Test both metrics on movie search results\n",
        "4. Understand the precision-recall trade-off\n",
        "\n",
        "**üí° Reference**: See Learning Notebook Part 2 - Evaluation Metrics section for detailed explanations!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "DThF1riqrJ_E",
        "outputId": "e9081734-efca-43f3-e64e-d54b94353eec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing your implementations:\n",
            "============================================================\n",
            "Ground truth: 8 relevant movies\n",
            "Search results: 10 returned\n",
            "\n",
            "K=1:\n",
            "  Precision@1: 1.000 (100.0%)\n",
            "  Recall@1:    0.125 (12.5%)\n",
            "\n",
            "K=3:\n",
            "  Precision@3: 0.667 (66.7%)\n",
            "  Recall@3:    0.250 (25.0%)\n",
            "\n",
            "K=5:\n",
            "  Precision@5: 0.600 (60.0%)\n",
            "  Recall@5:    0.375 (37.5%)\n",
            "\n",
            "K=10:\n",
            "  Precision@10: 0.500 (50.0%)\n",
            "  Recall@10:    0.625 (62.5%)\n",
            "\n",
            "============================================================\n",
            "Precision-Recall Trade-off:\n",
            "============================================================\n",
            "Notice what happens as K increases:\n",
            "  - Precision often decreases (more noise)\n",
            "  - Recall increases (finding more relevant docs)\n",
            "\n",
            "This is the fundamental trade-off in search systems!\n",
            "\n",
            "üí° Tips:\n",
            "  1. Precision measures quality: 'Are the results I show relevant?'\n",
            "  2. Recall measures completeness: 'Did I find all relevant results?'\n",
            "  3. You usually can't maximize both at the same time!\n",
            "\n",
            "üìö Reference: Learning Notebook Part 2, Evaluation Metrics section\n"
          ]
        }
      ],
      "source": [
        "# Exercise 8: Implement Precision@K and Recall@K\n",
        "\n",
        "from collections import Counter  # se ainda n√£o estiver importado\n",
        "\n",
        "def precision_at_k(relevant_ids, search_results, k):\n",
        "    \"\"\"\n",
        "    Calculate Precision@K.\n",
        "    \"\"\"\n",
        "    # Se K for 0, evitamos divis√£o por zero\n",
        "    if k == 0:\n",
        "        return 0.0\n",
        "\n",
        "    # Converter para set para procurar mais r√°pido\n",
        "    relevant_set = set(relevant_ids)\n",
        "\n",
        "    # Top-K resultados\n",
        "    top_k = search_results[:k]\n",
        "\n",
        "    # Contar quantos do top-K s√£o relevantes\n",
        "    relevant_in_top_k = sum(1 for doc_id in top_k if doc_id in relevant_set)\n",
        "\n",
        "    # Precision@K = relevantes no top-K / K\n",
        "    return relevant_in_top_k / k\n",
        "\n",
        "\n",
        "def recall_at_k(relevant_ids, search_results, k):\n",
        "    \"\"\"\n",
        "    Calculate Recall@K.\n",
        "    \"\"\"\n",
        "    total_relevant = len(relevant_ids)\n",
        "\n",
        "    # Se n√£o houver documentos relevantes, definimos recall como 0.0\n",
        "    if total_relevant == 0:\n",
        "        return 0.0\n",
        "\n",
        "    relevant_set = set(relevant_ids)\n",
        "    top_k = search_results[:k]\n",
        "\n",
        "    # Contar quantos relevantes aparecem no top-K\n",
        "    relevant_in_top_k = sum(1 for doc_id in top_k if doc_id in relevant_set)\n",
        "\n",
        "    # Recall@K = relevantes encontrados no top-K / total de relevantes\n",
        "    return relevant_in_top_k / total_relevant\n",
        "\n",
        "\n",
        "# Test with example data\n",
        "# Ground truth: these are the truly relevant movies for query \"space adventure\"\n",
        "relevant_movie_ids = [10, 25, 42, 67, 89, 103, 156, 201]  # 8 relevant total\n",
        "\n",
        "# Simulated search results (ranked by some search algorithm)\n",
        "search_results = [10, 15, 25, 30, 42, 55, 67, 70, 80, 89]  # Top 10 returned\n",
        "# Relevant in results: 10, 25, 42, 67, 89 (5 out of 10)\n",
        "\n",
        "print(\"Testing your implementations:\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Ground truth: {len(relevant_movie_ids)} relevant movies\")\n",
        "print(f\"Search results: {len(search_results)} returned\\n\")\n",
        "\n",
        "# Test at different K values\n",
        "for k in [1, 3, 5, 10]:\n",
        "    prec = precision_at_k(relevant_movie_ids, search_results, k)\n",
        "    rec = recall_at_k(relevant_movie_ids, search_results, k)\n",
        "    print(f\"K={k}:\")\n",
        "    print(f\"  Precision@{k}: {prec:.3f} ({prec*100:.1f}%)\")\n",
        "    print(f\"  Recall@{k}:    {rec:.3f} ({rec*100:.1f}%)\\n\")\n",
        "\n",
        "# Visualize the precision-recall trade-off\n",
        "print(\"=\"*60)\n",
        "print(\"Precision-Recall Trade-off:\")\n",
        "print(\"=\"*60)\n",
        "print(\"Notice what happens as K increases:\")\n",
        "print(\"  - Precision often decreases (more noise)\")\n",
        "print(\"  - Recall increases (finding more relevant docs)\")\n",
        "print(\"\\nThis is the fundamental trade-off in search systems!\")\n",
        "\n",
        "# Expected output (if implemented correctly):\n",
        "# K=1:  Precision=1.0 (100%), Recall=0.125 (12.5%)\n",
        "# K=10: Precision=0.5 (50%), Recall=0.625 (62.5%)\n",
        "\n",
        "print(\"\\nüí° Tips:\")\n",
        "print(\"  1. Precision measures quality: 'Are the results I show relevant?'\")\n",
        "print(\"  2. Recall measures completeness: 'Did I find all relevant results?'\")\n",
        "print(\"  3. You usually can't maximize both at the same time!\")\n",
        "print(\"\\nüìö Reference: Learning Notebook Part 2, Evaluation Metrics section\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lOFbmzNrJ_F"
      },
      "source": [
        "## Exercise 6: Implement MRR (Mean Reciprocal Rank)\n",
        "\n",
        "**Goal**: Implement MRR - a metric that measures how quickly users find a relevant result!\n",
        "\n",
        "**What you'll implement:**\n",
        "1. `reciprocal_rank()` - Calculate RR for a single query (1 / position of first relevant result)\n",
        "2. `mean_reciprocal_rank()` - Calculate MRR across multiple queries\n",
        "3. Understand when MRR is the right metric to use\n",
        "\n",
        "**Key Insight**: MRR is perfect for question-answering scenarios where users only need ONE good answer!\n",
        "\n",
        "**üí° Reference**: Learning Notebook Part 2, MRR section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "jOrV4-RKrJ_F",
        "outputId": "144b2797-4eb6-4487-de2c-2ddcbe1b2ea4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Reciprocal Rank:\n",
            "============================================================\n",
            "Search results: [5, 10, 15, 25, 42]\n",
            "Relevant IDs: [10, 25, 42]\n",
            "Reciprocal Rank: 0.500\n",
            "First relevant result at position: 2\n",
            "\n",
            "============================================================\n",
            "Testing Mean Reciprocal Rank (3 queries):\n",
            "============================================================\n",
            "Query 1: RR=1.000 (first relevant at position 1)\n",
            "Query 2: RR=0.333 (first relevant at position 3)\n",
            "Query 3: RR=0.250 (first relevant at position 4)\n",
            "\n",
            "Mean Reciprocal Rank: 0.528\n",
            "\n",
            "============================================================\n",
            "üí° When to use MRR:\n",
            "  ‚úÖ Question answering ('What is the capital of France?')\n",
            "  ‚úÖ Navigational search (user looking for a specific page)\n",
            "  ‚úÖ When users only need ONE good result\n",
            "  ‚ùå NOT good when users need multiple relevant results\n",
            "\n",
            "üìö Reference: Learning Notebook Part 2, MRR section\n"
          ]
        }
      ],
      "source": [
        "# Exercise 9: Implement MRR\n",
        "import numpy as np\n",
        "\n",
        "def reciprocal_rank(relevant_ids, search_results):\n",
        "    \"\"\"\n",
        "    Calculate Reciprocal Rank for a single query.\n",
        "    \"\"\"\n",
        "    relevant_set = set(relevant_ids)  # para lookup mais r√°pido\n",
        "\n",
        "    # percorrer resultados com posi√ß√£o a come√ßar em 1\n",
        "    for position, doc_id in enumerate(search_results, start=1):\n",
        "        if doc_id in relevant_set:\n",
        "            return 1.0 / position  # RR = 1 / posi√ß√£o do primeiro relevante\n",
        "\n",
        "    # se n√£o houver nenhum relevante nos resultados\n",
        "    return 0.0\n",
        "\n",
        "\n",
        "def mean_reciprocal_rank(relevant_ids_list, search_results_list):\n",
        "    \"\"\"\n",
        "    Calculate Mean Reciprocal Rank across multiple queries.\n",
        "    \"\"\"\n",
        "    rr_scores = []\n",
        "\n",
        "    for rel_ids, results in zip(relevant_ids_list, search_results_list):\n",
        "        rr = reciprocal_rank(rel_ids, results)\n",
        "        rr_scores.append(rr)\n",
        "\n",
        "    if len(rr_scores) == 0:\n",
        "        return 0.0\n",
        "\n",
        "    return float(np.mean(rr_scores))\n",
        "\n",
        "\n",
        "# Test with example data\n",
        "print(\"Testing Reciprocal Rank:\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Single query example\n",
        "relevant = [10, 25, 42]\n",
        "results = [5, 10, 15, 25, 42]  # First relevant at position 2\n",
        "rr = reciprocal_rank(relevant, results)\n",
        "print(f\"Search results: {results}\")\n",
        "print(f\"Relevant IDs: {relevant}\")\n",
        "print(f\"Reciprocal Rank: {rr:.3f}\")\n",
        "print(f\"First relevant result at position: {1/rr:.0f}\" if rr > 0 else \"No relevant result\")\n",
        "\n",
        "# Multiple queries example\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Testing Mean Reciprocal Rank (3 queries):\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "queries_relevant = [\n",
        "    [10, 25, 42],       # Query 1 relevant IDs\n",
        "    [5, 15, 30],        # Query 2 relevant IDs\n",
        "    [1, 2, 3]           # Query 3 relevant IDs\n",
        "]\n",
        "\n",
        "queries_results = [\n",
        "    [10, 11, 12, 13],   # Query 1: first relevant at position 1 ‚Üí RR=1.0\n",
        "    [20, 21, 15, 22],   # Query 2: first relevant at position 3 ‚Üí RR=0.333\n",
        "    [50, 51, 52, 1],    # Query 3: first relevant at position 4 ‚Üí RR=0.25\n",
        "]\n",
        "\n",
        "for i, (rel, res) in enumerate(zip(queries_relevant, queries_results), 1):\n",
        "    rr = reciprocal_rank(rel, res)\n",
        "    pos = int(1/rr) if rr > 0 else \"N/A\"\n",
        "    print(f\"Query {i}: RR={rr:.3f} (first relevant at position {pos})\")\n",
        "\n",
        "mrr = mean_reciprocal_rank(queries_relevant, queries_results)\n",
        "print(f\"\\nMean Reciprocal Rank: {mrr:.3f}\")\n",
        "\n",
        "# Expected output (if implemented correctly):\n",
        "# Query 1: RR=1.0, Query 2: RR=0.333, Query 3: RR=0.25\n",
        "# MRR = (1.0 + 0.333 + 0.25) / 3 = 0.528\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üí° When to use MRR:\")\n",
        "print(\"  ‚úÖ Question answering ('What is the capital of France?')\")\n",
        "print(\"  ‚úÖ Navigational search (user looking for a specific page)\")\n",
        "print(\"  ‚úÖ When users only need ONE good result\")\n",
        "print(\"  ‚ùå NOT good when users need multiple relevant results\")\n",
        "print(\"\\nüìö Reference: Learning Notebook Part 2, MRR section\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRn5skO0rJ_F"
      },
      "source": [
        "## Exercise 7: Implement NDCG@K (Normalized Discounted Cumulative Gain)\n",
        "\n",
        "**Goal**: Implement NDCG - the most comprehensive ranking quality metric!\n",
        "\n",
        "**What makes NDCG special:**\n",
        "- Considers **position** - results at top are more valuable\n",
        "- Measures **ranking quality** - not just presence/absence\n",
        "- **Normalized** - always between 0 and 1 (easier to compare)\n",
        "\n",
        "**What you'll implement:**\n",
        "1. `dcg_at_k()` - Calculate Discounted Cumulative Gain\n",
        "2. `ndcg_at_k()` - Normalize DCG by ideal ranking (IDCG)\n",
        "3. Compare with Precision/Recall to see the difference\n",
        "\n",
        "**üí° Reference**: Learning Notebook Part 2, NDCG section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "tnkbw1vjrJ_G",
        "outputId": "0e17f7a9-e027-4f4a-ab3d-681e85ade29e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing NDCG Implementation:\n",
            "======================================================================\n",
            "Ground truth: 5 relevant movies\n",
            "Search results (top 10): [10, 15, 25, 30, 42, 55, 67, 70, 80, 89]\n",
            "\n",
            "NDCG at different K values:\n",
            "----------------------------------------------------------------------\n",
            "NDCG@1: 1.000\n",
            "NDCG@3: 0.704\n",
            "NDCG@5: 0.640\n",
            "NDCG@10: 0.851\n",
            "\n",
            "======================================================================\n",
            "Comparing All Metrics at K=10:\n",
            "======================================================================\n",
            "Precision@10: 0.500 - What % of top-10 are relevant?\n",
            "Recall@10:    1.000 - What % of all relevant found?\n",
            "NDCG@10:      0.851 - How good is the ranking?\n",
            "RR:            1.000 - Position of first relevant result\n",
            "\n",
            "======================================================================\n",
            "üí° Key Insights:\n",
            "======================================================================\n",
            "1. NDCG rewards putting relevant results at the TOP\n",
            "2. NDCG penalizes relevant results buried at the BOTTOM\n",
            "3. Precision/Recall don't care about position - only presence\n",
            "4. NDCG is the most comprehensive ranking quality metric!\n",
            "\n",
            "üìö Reference: Learning Notebook Part 2, NDCG section\n"
          ]
        }
      ],
      "source": [
        "# Exercise 10: Implement NDCG@K\n",
        "import numpy as np\n",
        "\n",
        "def dcg_at_k(relevances, k):\n",
        "    \"\"\"\n",
        "    Calculate Discounted Cumulative Gain at K.\n",
        "    \"\"\"\n",
        "    # Considerar s√≥ os top-k\n",
        "    rels = np.array(relevances[:k], dtype=float)\n",
        "\n",
        "    if rels.size == 0:\n",
        "        return 0.0\n",
        "\n",
        "    # posi√ß√µes 1,2,3,... (porque o DCG √© 1/log2(pos+1) com pos a come√ßar em 1)\n",
        "    positions = np.arange(1, rels.size + 1)\n",
        "\n",
        "    # desconto: log2(position + 1)\n",
        "    discounts = np.log2(positions + 1)\n",
        "\n",
        "    # DCG = soma( relevance_i / log2(position_i + 1) )\n",
        "    dcg = np.sum(rels / discounts)\n",
        "    return float(dcg)\n",
        "\n",
        "\n",
        "def ndcg_at_k(relevant_ids, search_results, k):\n",
        "    \"\"\"\n",
        "    Calculate Normalized Discounted Cumulative Gain at K.\n",
        "    \"\"\"\n",
        "    relevant_set = set(relevant_ids)\n",
        "\n",
        "    # Step 1 ‚Äì relev√¢ncias reais dos resultados (1 se relevante, 0 se n√£o)\n",
        "    top_k_results = search_results[:k]\n",
        "    actual_relevances = [1 if doc_id in relevant_set else 0 for doc_id in top_k_results]\n",
        "\n",
        "    # Step 2 ‚Äì DCG da ordem real\n",
        "    dcg = dcg_at_k(actual_relevances, k)\n",
        "\n",
        "    # Step 3 ‚Äì relev√¢ncias ideais: todos os relevantes primeiro\n",
        "    num_relevant = min(len(relevant_set), k)\n",
        "    ideal_relevances = [1] * num_relevant + [0] * max(0, k - num_relevant)\n",
        "\n",
        "    # Step 4 ‚Äì DCG da ordem ideal (IDCG)\n",
        "    idcg = dcg_at_k(ideal_relevances, k)\n",
        "\n",
        "    # Step 5 ‚Äì normalizar\n",
        "    if idcg == 0:\n",
        "        return 0.0\n",
        "\n",
        "    return float(dcg / idcg)\n",
        "\n",
        "\n",
        "\n",
        "# Test with example data\n",
        "print(\"Testing NDCG Implementation:\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Ground truth\n",
        "relevant_movie_ids = [10, 25, 42, 67, 89]\n",
        "\n",
        "# Search results: some relevant, some not\n",
        "search_results = [10, 15, 25, 30, 42, 55, 67, 70, 80, 89]\n",
        "# Relevance pattern: [1, 0, 1, 0, 1, 0, 1, 0, 0, 1]\n",
        "\n",
        "print(f\"Ground truth: {len(relevant_movie_ids)} relevant movies\")\n",
        "print(f\"Search results (top 10): {search_results}\\n\")\n",
        "\n",
        "# Calculate NDCG at different K values\n",
        "print(\"NDCG at different K values:\")\n",
        "print(\"-\"*70)\n",
        "for k in [1, 3, 5, 10]:\n",
        "    ndcg = ndcg_at_k(relevant_movie_ids, search_results, k)\n",
        "    print(f\"NDCG@{k}: {ndcg:.3f}\")\n",
        "\n",
        "# Compare all metrics together\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Comparing All Metrics at K=10:\")\n",
        "print(\"=\"*70)\n",
        "k = 10\n",
        "\n",
        "prec = precision_at_k(relevant_movie_ids, search_results, k)\n",
        "rec = recall_at_k(relevant_movie_ids, search_results, k)\n",
        "ndcg = ndcg_at_k(relevant_movie_ids, search_results, k)\n",
        "rr = reciprocal_rank(relevant_movie_ids, search_results)\n",
        "\n",
        "print(f\"Precision@{k}: {prec:.3f} - What % of top-{k} are relevant?\")\n",
        "print(f\"Recall@{k}:    {rec:.3f} - What % of all relevant found?\")\n",
        "print(f\"NDCG@{k}:      {ndcg:.3f} - How good is the ranking?\")\n",
        "print(f\"RR:            {rr:.3f} - Position of first relevant result\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üí° Key Insights:\")\n",
        "print(\"=\"*70)\n",
        "print(\"1. NDCG rewards putting relevant results at the TOP\")\n",
        "print(\"2. NDCG penalizes relevant results buried at the BOTTOM\")\n",
        "print(\"3. Precision/Recall don't care about position - only presence\")\n",
        "print(\"4. NDCG is the most comprehensive ranking quality metric!\")\n",
        "print(\"\\nüìö Reference: Learning Notebook Part 2, NDCG section\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VADxv2DrJ_G"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bUkiqO9rJ_H"
      },
      "source": [
        "i"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASfrIqvUrJ_H"
      },
      "source": [
        "## Summary: What You've Practiced in Part 2\n",
        "\n",
        "‚úÖ TF-IDF from Scratch (IDF calculation + full TF-IDF)  \n",
        "‚úÖ Build TF-IDF Vectors from Scratch (complete vectorization)  \n",
        "‚úÖ Similarity-Based Search with TF-IDF (cosine similarity)  \n",
        "‚úÖ Hybrid Search (combining TF-IDF + keyword matching)  \n",
        "‚úÖ Compare Search Methods (keyword vs TF-IDF vs hybrid)  \n",
        "\n",
        "\n",
        "**Key Takeaways:**\n",
        "- TF-IDF improves on BoW by weighting words by importance (TF √ó IDF)\n",
        "- IDF measures word rarity across documents (rare words = more informative)\n",
        "- Cosine similarity measures document similarity regardless of length\n",
        "- Similarity search is better than keyword search but still keyword-based (not truly semantic)\n",
        "- Hybrid search combines the best of both: keyword precision + TF-IDF recall\n",
        "- True semantic search requires embeddings (Class 3!)\n",
        "\n",
        "\n",
        "**üéâ Congratulations!** You've built a complete search system from scratch! You now understand:\n",
        "- How to convert text to numbers (BoW, TF-IDF)\n",
        "- How to measure similarity (cosine similarity)\n",
        "- How to search and rank documents\n",
        "- How to combine multiple search strategies (hybrid search)\n",
        "\n",
        "**Next Steps**:\n",
        "- Continue with **Exercise Notebook Part 3** to practice using industry tools (NLTK, spaCy, scikit-learn)!\n",
        "- Review the Learning Notebooks\n",
        "- Continue with Class 3 for embeddings and semantic search!\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}